# Log Stats collection spec 
# Author: havembha@gmail.com,  2021/07/18
# Format
# - LogFile: <file name including path name> - use regular expression syntax to specify a file whose 
#         name may change from one host to another or with time (file name with date/time)
#   - ServiceName: service name that identifies the pattern being searched
#         use this to tie log pattern to many services offered by that process
#         use UpperCase letters to separate words, use letters [a-z|A-Z|0-9] in name
#     PatternPass: string in regular expression syntax to idicate pass instance
#         presence of this string in a line will increment metric <ServiceName>_pass 
#     PatternFail: string in regular expression syntax to idicate pass instance
#         presence of this string in a line will increment metric <ServiceName>_fail
#     PatternCount: string in regular expression syntax to idicate pass instance
#         presence of this string in a line will increment metric <ServiceName>_count
#         use this when Pass or Fail is not needed, just need to account for an incident like alarms
#     Priority: 1 or 2 or 3, default 3
#         This pattern will be searched when currnet average CPU usage is below MaxCPUUsageForEvents[priority]
#
#     PatternSum: leading text (\w+) text (\d+) text (\w+) text (\d+) ....
#                               key1      value1      key2       value2
#         Prometheus metrics ServiceName_keyx_sum
#                value is summed over sampling interval and divided by sampling interval to derive tps
#
#     PatternAverage: leading text (\w+) text (\d+) text (\w+) text (\d+) ....
#                               key1      value1      key2       value2
#         Prometheus metrics ServiceName_keyx_average
#                value is summed over sampling interval and divided by number of samples within that sammpling interval
#
#     PatternDelta: leading text (\w+) text (\d+) text (\w+) text (\d+) ....
#                               key1      value1      key2       value2
#         Prometheus metrics ServiceName_keyx_delta
#                current value is subtracted from previous sample value and summed over the sampling period.
#                at the end of sampling period, tps is calcuated by dividing the sum with sampling period. 
#                When the this script starts, first sample value is stored as previous value, any change from the value seen
#                  in previous run to current run is not computed to keep the tool simple.
#
#     PatternVariablePrefix: extract the regular expression value that matches to the variable prefix definition
#           prefix that to the variable to make unique value
#          serviceName_<variablePrefix>_<patterDelta>_delta
#                                          ^^
#     PatternVariablePrefixGroup: While matching the variable prefix pattern, if the group to be used is not the first one,
#                          use this to specify group number (see example below for more info)
# 
#
#     PatternLog: send this log line to web server with jobName=loki so that log line is posted to loki gateway
#                 all log lines of a log file are combined and sent to web server
#                 log lines of different log files are sent with different label value
#                 label name is set to hostname from where log is collected
#                 Unlike all other pattern search, after matching PatternLog, search will continue so that
#                   pattern occurrence will be counted for a log line that is collected
#
#     NOTE - for all patterns above for a given service, 
#               once a search matches, no further search done to match other patterns
#               search for PatternLog continues so that log line collection can still be done after pattern match
#                        within the same service defintion.
#            Across all services, 
#                If log pattern match or stats pattern match for any given service, search stops
#           If search for pattern stats and log are same need to put that under same service name
#           In order to optimize the processing time, it is recommended to put frequently occuring patterns
#            at the beginning of a log file. Less frequently occuring patterns at the end of the list.
#
# NOTE - make no space after pattern strings
#  Escape regular expression special characters in pattern spec like \/
#   Non-special characters match themselves. Special characters don't match themselves −
#
#     \    Escape special char or start a sequence.
#     .    Match any char except newline, see re.DOTALL
#     ^    Match start of the string, see re.MULTILINE
#     $    Match end of the string, see re.MULTILINE
#     [ ]  Enclose a set of matchable chars
#     R|S  Match either regex R or regex S.
#     ()   Create capture group, & indicate precedence
#
#     After '[', enclose a set, the only special chars are −
#      ]    End the set, if not the 1st char
#      -    A range, eg. a-c matches a, b or c
#      ^    Negate the set only if it is the 1st char
#
#     Quantifiers (append '?' for non-greedy) −
#      {m}   Exactly m repetitions
#      {m,n} From m (default 0) to n (default infinity)
#      *     0 or more. Same as {,}
#      +     1 or more. Same as {1,}
#      ?     0 or 1. Same as {,1}
#  For more info on regular expression, refer https://docs.python.org/3/library/re.html
#
#  below section is to execute command on target host, collect stats, log that to log file
#    so that log file processing section can gather application stats and post to web server
#  Execute
#    <CommandSectionName> unique name to specify command information
#    <IntervalInSec> - how often to execute this command
#                     like 60 for every min, 600 for every 10 min
---
GatherLogStatsLogFile: JAGatherLogStats.log
GatherLogStatsCacheFile: JAGatherLogStats.cache
Environment:
   Dev:
     HostName: ((...)(d)(...)([0-9][0-9]))|(LAPTOP-QOCNVF0T)
     ### save logs on web server (local cache, in addition to sending to loki)
     SaveLogsOnWebServer: True
   Test:
     HostName: (...)(t)(...)([0-9][0-9])
     ### save logs on web server (local cache, in addition to sending to loki)
     SaveLogsOnWebServer: True
   UAT:
     HostName: (...)(u)(...)([0-9][0-9])
     WebServerURL: https://192.168.1.221:443/cgi-bin/JASaveStats.py
   Prod:
     HostName: (...)(p)(...)([0-9][0-9])
     WebServerURL: https://192.168.1.221:443/cgi-bin/JASaveStats.py
     
  ## Keep definition for 'All' environment at the end.
  ##  this is to ensure, Dev, Test, UAT, Prod etc environment specific values are seen/read first and 
  ##  assigned to variables. If a variable is not yet defined under Dev, Test.. like environment,
  ##  and that variable is defined under 'All', value under 'All' will be picked up
  ##  if variable is already defined under environment before, value under 'All' will be ignored.
   All:
     # max time allowed for log file processing during each sampling interval
     #  below 30 second value is half of 60 seconds specified for sampling interval
     MaxProcessingTimeForAllEvents: 30
     # post data to web server per this interval. if sampling interval is 10, post interval is 60,
     #    it will post 6 samples in one post. This is to optimize data post operation.
     DataPostIntervalInSec: 60
     # once the job is started, run until this time. This is to allow job running from crontab at certain periodicity 
     DataCollectDurationInSec: 600
     ### SKIP gathering log stats when average CPU usage % exceeds below limit over previous
     ###   10 DataPostIntervalInSec intervals
     MaxCPUUsageForAllEvents: 80
     ### SKIP gathering log stats with priority 1 when average CPU usage % exceeds below limit
     MaxCPUUsageForPriority1Events: 70
     ### SKIP gathering log stats with priority 2 when average CPU usage % exceeds below limit
     MaxCPUUsageForPriority2Events: 60
     ### SKIP gathering log stats with priority 3 when average CPU usage % exceeds below limit
     MaxCPUUsageForPriority3Events: 50
     ### max log lines per service, per sampling interval
     ###  when log lines exceed this count, from 11th line till last line withing the sampling interval,
     ###    lines will be counted and reported as "..... XXX more lines...."
     ### this is to reduce the data sent to central web server, posted to loki, cached by loki and stored under grafana
     MaxLogLines: 10
     ### Do not save logs on web server (local cache, in addition to sending to loki)
     SaveLogsOnWebServer: False
     ### while posting data to web server, defaults to False
     DisableWarnings: True
     ### do not verify web server certificate, defaults to True
     VerifyCertificate: False
     # post stats to below web server
     WebServerURL: https://192.168.1.221:443/cgi-bin/JASaveStats.py
     ### debug level 0, no debug, 1 to 4, 4 being max details
     DebugLevel: 1

Execute:
    Health:
      ### execute below command to gather application stats, output to log file
      Command: tasklist | select-string JATest.py > Health.log
      IntervalInSec: 60
      Priority: 2
    Uptime:
      Command: echo "systeminfo | select-string 'Boot Time'" >> Health.log ; systeminfo | select-string "Boot Time" >> Health.log 
      IntervalInSec: 600
      Priority: 3

LogFile:
    SyslogError:
      LogFileName: /var/log/syslog
      #LogFileName: /var/log/{HOSTNAME}syslog
      PatternCount: Error
      Priority: 3

    SyslogSession:
      LogFileName: /var/log/syslog
      PatternCount: Started Session
      Priority: 3

    AuthlogInvalidUser:
      LogFileName: /var/log/auth.log
      PatternCount: Invalid user
      Priority: 3

    ApacheGrafana:
      LogFileName: /var/log/apache2/access.log*
      PatternPass: /grafana(.*)HTTP/\d.\d" [2..|3..]
      PatternFail: /grafana(.*)HTTP/\d.\d" [4..|5..]
      Priority: 2
  
    ApachePrometheus:
      LogFileName: /var/log/apache2/access.log*
      PatternPass: /prometheus(.*)HTTP/\d.\d" [2..|3..]
      PatternFail: /prometheus(.*)HTTP/\d.\d" [4..|5..]
      Priority: 2

    ApacheSaveStats:
      LogFileName: /var/log/apache2/access.log*
      PatternPass: /JASaveStats.py(.*)HTTP/\d.\d" [2..|3..]
      PatternFail: /JASaveStats.py(.*)HTTP/\d.\d" [4..|5..]
      Priority: 1

    ApacheError:
      LogFileName: /var/log/apache2/error.log* 
      PatternCount: \[cgi:error\] 
      Priority: 1

    TestStats:
      LogFileName: client/JATest.log*
      ### tps = number of instances divided by sampling interval
      PatternPass: TestMsg Pass
      ### tps = number of instances divided by sampling interval
      PatternFail: TestMsg Fail
      PatternLog: TestMsg Fail
      ### tps = number of instances divided by sampling interval
      PatternCount: TestMsg Count
      # PatternSum: leading text key1 dummy value1 dummy key2 dummy value2 dummy....
      # value is summed over the sampling interval, tps is computed by diving sampling interval
      # line is of the form: 2021-09-18T14:57:07.088995 leading text key1 54 dummy1 key2 27.00 dummy2
      #                                                              kkkk vv        kkkk vvvvv
      PatternSum: leading text (\w+) (\d+) dummy1 (\w+) (\d+.\d+) dummy
      # PatternAverage: leading text key1 dummy value1 dummy key2 dummy value2 dummy....
      # value is summed over the sampling interval, average value is computed by dividing number of samples in that sampling interval
      # line is of the form: 2021-09-18T14:57:07.088995 tps key1 54 dummy1 key2 27.00 dummy2
      #                                                     kkkk  vv       kkkk vvvvv
      # PatternAverage: tps (\w+) (\d+) dummy1 (\w+) (\d+.\d+) dummy  
      # PatternDelta: leading text (\w+) (\d+) dummy1 (\w+) (\d+.\d+) dummy
      # prev sample value is subracted from current sample to find the change or delta value.
      # these delta values are summed over the sampling interval and divided by sampling intervall to get tps
      # line is of the form: 2021-09-18T14:57:07.089993 total key1 9 dummy1 total key2 4.50 dummy2
      #                                                       kkkk v              kkkk vvvv
      PatternDelta: tps (\w+) (\d+) dummy1 total (\w+) (\d+.\d+) dummy

    TestStatsWithVarPrefix:
      LogFileName: client/JATest.log*
      ### extract the regular expression value that matches to the variable prefix definition
      ###   prefix that to the variable to make unique value
      ###   serviceName_<variablePrefix>_<patterDelta>_delta
      PatternVariablePrefix: Stats MicroService(\d) total
      # 2021-10-05T01:09:03.249334 Stats MicroService1 total key1 9 dummy1 total key2 4.50 dummy2
      PatternAverage: total (\w+) (\d+) dummy1 total (\w+) (\d+.\d+) dummy2
      Priority: 1
    TestStatsWithVarPrefixGroup:
      LogFileName: client/JATest.log*
      ### extract the regular expression value that matches to the variable prefix definition
      ###   prefix that to the variable to make unique value
      ###   serviceName_<variablePrefix>_<patterDelta>_delta
      PatternVariablePrefix: Stats MicroService(\d)(\d) total
      ###                                           ^^
      ###  use 2nd group value as variable prefix for the *_avrage metrics variable
      PatternVariablePrefixGroup: 2
      # 2021-10-05T01:09:03.249334 Stats MicroService25 total key1 9 dummy1 total key2 4.50 dummy2
      PatternAverage: total (\w+) (\d+) dummy1 total (\w+) (\d+.\d+) dummy2
      Priority: 1